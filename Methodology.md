### Methodology üìäüí°

**Overview of Instrumented Principal Component Analysis (IPCA) üß©**

Instrumented Principal Component Analysis (IPCA) is a fancy statistical method we use to analyze and predict how currency exchange rates might change over time. Think of it as a super-smart tool that helps us find hidden patterns in a lot of complex data.

**Factor Model for Currency Returns üíπ**

In finance, a **factor model** is used to explain the returns (profits or losses) on investments based on various factors. For example, factors might include things like interest rates, inflation, or stock market performance. 

**Key Components of Our Model üîë**

1. **Currency Return (ri,t+1) üíµ‚û°Ô∏èüìà**: This represents how much the value of a currency changes over a certain period. For instance, if you invest in euros, this tells you how much your investment has increased or decreased.

2. **Latent Factors (ft+1) üîç**: These are the hidden factors that affect currency returns. We don't directly observe them, but they play a crucial role in determining how currencies perform.

3. **Beta Coefficients (Œ≤i,t) üìà‚û°Ô∏èüíµ**: These numbers show how sensitive a currency's return is to changes in the latent factors. Imagine beta coefficients as the "volume knobs" that adjust the impact of different factors on the currency returns.

**Dynamic Factor Loadings üîÑ**

In traditional models, beta coefficients are assumed to be constant, like fixed dials on a machine. However, in reality, these coefficients can change over time based on economic conditions. Our model allows these "volume knobs" (beta coefficients) to move up and down as conditions change, making our predictions more accurate.

**Country Characteristics as Instruments üåçüìä**

We use specific characteristics of countries (like interest rates, inflation rates, etc.) as instruments to help our model. These characteristics help us better understand how the beta coefficients should change over time. It's like having extra clues that help us solve a puzzle more efficiently.

**Statistical Link and Efficiency üîó‚ö°**

By linking the beta coefficients to country characteristics, we can make our model more efficient and accurate. This means we can get better predictions using less data, which is always a good thing in complex financial analysis.

**Data Collection üìÖüìà**

We collected data on exchange rates and various economic factors from G10 countries (Australia, Canada, Switzerland, Denmark, Euro Area, UK, Japan, Norway, New Zealand, and Sweden) from January 2008 to December 2020. This gives us a broad and diverse dataset to work with.

**Model Estimation Process üìè**

The process of estimating our model involves adjusting the beta coefficients and other parameters to best fit the historical data. This is done using a technique called **alternating least squares**, which helps find the best-fitting values by minimizing errors.

**Performance Measures üìä**

To evaluate how well our model performs, we use two key measures:

1. **Total R-squared (R¬≤) üìà**: This tells us how much of the variation in currency returns our model can explain. A higher R¬≤ means our model is doing a good job.
   
2. **Predictive R-squared (R¬≤) üîÆ**: This measures how well our model can predict future currency returns based on past data. This is crucial because it shows whether our model is useful for making real-world predictions.

**Bootstrap Procedure ü•æ**

To make sure our results are reliable, we use a statistical method called bootstrapping. This involves repeatedly sampling from our data to test the stability of our findings. Think of it as doing multiple trial runs to ensure our model's predictions are consistent and trustworthy.

**In-Sample vs. Out-of-Sample Tests üîÑüî¨**

We divide our data into two parts: 
- **In-Sample Period**: The first ten years of data, which we use to train our model.
- **Out-of-Sample Period**: The last three years of data, which we use to test our model's predictions.

---

### Factor Model for Currency Returns üìâüíµ

The factor model for currency returns is a way to understand and predict how the value of a currency changes over time based on various underlying factors. Let's break down the key components:

**1. Currency Return (ri,t+1) üíµ‚û°Ô∏èüìà**
- **Definition**: Currency return refers to how much the value of a currency changes over a specific period.
- **Example**: Imagine you invest in euros (EUR) at the start of the month. By the end of the month, the value of the euros you hold has increased by 2%. This 2% change is the currency return.

**2. Beta Coefficients (Œ≤i,t) üìà‚û°Ô∏èüíµ**
- **Definition**: Beta coefficients are numbers that measure the sensitivity of the currency return to changes in underlying factors. Think of them as "sensitivity dials" that adjust how strongly different factors affect the currency return.
- **Example**: If the beta coefficient for interest rates (one of the factors) is 0.5, it means that for every 1% change in interest rates, the currency return changes by 0.5%. If the interest rate increases by 2%, the currency return would increase by 1% (0.5 * 2%).

**3. Latent Factors (ft+1) üîç**
- **Definition**: Latent factors are hidden or underlying variables that influence currency returns. These factors are not directly observed but can be inferred from the data.
- **Example**: Some latent factors might include economic growth, geopolitical events, or changes in investor sentiment. For instance, if there's a major geopolitical event, it might affect currency values, even though the exact impact (latent factor) isn't directly measured.

**4. Error Term (œµi,t+1) ‚ùå**
- **Definition**: The error term represents the part of the currency return that cannot be explained by the model. It's the "noise" or random fluctuations that are unpredictable.
- **Example**: If you predicted the currency return to be 2%, but it actually turns out to be 2.5%, the extra 0.5% is the error term. This could be due to random market movements or unexpected news.

### Alternating Least Squares (ALS) üßÆüîÑ

**Concept**:
Alternating Least Squares is a method used to estimate the parameters (like beta coefficients) in a factor model. It works by iteratively refining these estimates to minimize the difference between the predicted and actual currency returns.

**How ALS Works in Simple Terms**:

1. **Initial Guess üéØ**: Start with an initial guess for the beta coefficients and the latent factors.
   - **Example**: Let's say you start with a guess that the beta coefficient for interest rates is 0.4 and for economic growth is 0.3.

2. **Fix and Optimize üîß**: First, keep the beta coefficients fixed and optimize the latent factors to best fit the observed currency returns.
   - **Example**: Adjust the values of the latent factors (like changes in economic growth or geopolitical events) so that, given your beta coefficients, the predicted currency returns are as close as possible to the actual returns.

3. **Swap and Optimize üîÑ**: Next, keep the latent factors fixed and optimize the beta coefficients.
   - **Example**: Now, adjust the beta coefficients while keeping the latent factors constant to minimize the prediction error.

4. **Iterate ‚ôªÔ∏è**: Repeat these steps, alternating between optimizing the beta coefficients and the latent factors, until the changes are very small, meaning you've found the best fit.
   - **Example**: Keep refining the beta coefficients and latent factors back and forth until your predictions for currency returns are as close as possible to the actual returns over multiple iterations.

Here's a detailed breakdown of Module 2: Introduction to Instrumental Variables (IV):

---

## Introduction to Instrumental Variables (IV)

### 1. What are Instrumental Variables?
Instrumental Variables (IV) are used in statistical models to address the problem of endogeneity, where an explanatory variable is correlated with the error term. This correlation can lead to biased and inconsistent estimates. IVs help in isolating the exogenous variation in the explanatory variables.

#### 1.1 Definition and Purpose
- **Definition**: An instrumental variable is a variable that is correlated with the endogenous explanatory variable and uncorrelated with the error term in the model.
- **Purpose**: IVs are used to provide consistent estimates of the parameters in the presence of endogeneity. They help in achieving causal inference by removing the bias caused by omitted variables, measurement errors, or simultaneous causality.

### 2. Conditions for a Valid Instrument
For an instrumental variable to be valid, it must satisfy two key conditions:

#### 2.1 Relevance
- **Relevance Condition**: The instrument must be correlated with the endogenous explanatory variable. This ensures that the instrument can explain some of the variations in the endogenous variable.
- **Mathematical Representation**: \( Cov(Z, X) \neq 0 \)
  - Where \( Z \) is the instrumental variable and \( X \) is the endogenous explanatory variable.

#### 2.2 Exogeneity
- **Exogeneity Condition**: The instrument must be uncorrelated with the error term in the model. This ensures that the instrument is not capturing any of the noise or bias present in the endogenous variable.
- **Mathematical Representation**: \( Cov(Z, \epsilon) = 0 \)
  - Where \( \epsilon \) is the error term in the regression model.

### 3. IV in Econometrics
Instrumental variables are a fundamental tool in econometrics, particularly when dealing with endogeneity problems in regression models.

#### 3.1 Addressing Endogeneity
- **Endogeneity Problem**: Arises when an explanatory variable is correlated with the error term, leading to biased estimates.
- **Sources of Endogeneity**:
  - **Omitted Variable Bias**: When a relevant variable is left out of the model, causing the included variables to pick up the effect.
  - **Measurement Error**: Errors in measuring the explanatory variables can lead to correlation with the error term.
  - **Simultaneity**: When the explanatory variable is determined simultaneously with the dependent variable, leading to a two-way causation.

#### 3.2 Examples and Applications
- **Example 1: Supply and Demand Model**
  - **Scenario**: Estimating the price elasticity of demand.
  - **Endogeneity**: Price and quantity demanded are simultaneously determined.
  - **Instrument**: Weather conditions affecting supply but not directly affecting demand.
- **Example 2: Education and Earnings**
  - **Scenario**: Estimating the return to education.
  - **Endogeneity**: Ability and motivation (unobserved factors) influence both education and earnings.
  - **Instrument**: Distance to the nearest college, affecting education levels but not directly affecting earnings.

### 4. Instrumental Variable Estimation
#### 4.1 Two-Stage Least Squares (2SLS)
- **First Stage Regression**: Regress the endogenous explanatory variable on the instruments to obtain the fitted values (predicted values).
  - **Equation**: \( X = \pi_0 + \pi_1 Z + u \)
  - Where \( X \) is the endogenous variable, \( Z \) is the instrument, and \( u \) is the error term.
- **Second Stage Regression**: Regress the dependent variable on the fitted values from the first stage.
  - **Equation**: \( Y = \beta_0 + \beta_1 \hat{X} + \epsilon \)
  - Where \( \hat{X} \) are the fitted values from the first stage regression.

#### 4.2 Instrumental Variables in Practice
- **Choosing Instruments**: Select variables that are theoretically justifiable and satisfy the relevance and exogeneity conditions.
- **Testing Instruments**: Use statistical tests (e.g., weak instrument test, overidentification test) to verify the validity of the instruments.

### Summary
Instrumental variables are crucial in addressing endogeneity issues in regression models. By satisfying the relevance and exogeneity conditions, IVs help in obtaining consistent and unbiased estimates. The two-stage least squares (2SLS) method is commonly used to implement IV estimation in practice. Understanding and correctly applying IVs is essential for causal inference in econometric analysis.

---

Sure! Here's a detailed breakdown of Module 3: Combining PCA with Instrumental Variables (IPCA):

---

## Module 3: Combining PCA with Instrumental Variables (IPCA)

### 1. What is IPCA?
Instrumented Principal Component Analysis (IPCA) is an extension of the standard PCA technique that incorporates instrumental variables to handle endogeneity. IPCA is used to extract latent factors from data while addressing the problem of endogeneity in the explanatory variables.

#### 1.1 Definition and Motivation
- **Definition**: IPCA is a statistical method that combines the principles of PCA and instrumental variables to provide a more robust dimensionality reduction technique in the presence of endogeneity.
- **Motivation**: In many real-world applications, the explanatory variables may be endogenous. Standard PCA may produce biased factors if endogeneity is present. IPCA addresses this by using instruments to correct for endogeneity before performing PCA.

### 2. The IPCA Algorithm

---

### 1. Introduction to IPCA in the Research Paper Context
In the research paper, the authors aim to predict foreign exchange (FX) market returns using Instrumented Principal Component Analysis (IPCA). They address the issue of time-varying beta coefficients and improve model predictability by leveraging IPCA.

### 2. The IPCA Algorithm Step-by-Step

#### 2.1 Data Preparation
- **Collect and Standardize Data**: The paper collects FX spot and forward rates from Datastream, covering the period from January 2008 to December 2020, for G10 countries. They standardize the data to ensure consistency.
- **Identify Instrumental Variables**: The study uses macroeconomic and financial variables such as interest rate differentials, stock market momentum, and idiosyncratic volatility as instrumental variables.

#### 2.2 Model Specification
- **Define the Model**: The IPCA model is specified to account for time-varying betas by incorporating country-specific characteristics into the factor model. The model equation is:
  \[
  r_{i,t+1} = \alpha_{i,t} + \beta_{i,t} f_{t+1} + \epsilon_{i,t+1}
  \]
  where \( r_{i,t+1} \) is the return of asset \( i \) at time \( t+1 \), \( \alpha_{i,t} \) is the intercept, \( \beta_{i,t} \) are the factor loadings, and \( f_{t+1} \) are the latent factors.
- **Select Instruments**: Instruments \( Z_{i,t} \) are selected to ensure they are correlated with the endogenous variables and uncorrelated with the error term. The characteristics \( z_{i,t} \) include macroeconomic conditions and financial indicators.

#### 2.3 First Stage Regression
- **Regress Endogenous Variables on Instruments**: Each endogenous variable is regressed on the instrumental variables to isolate the exogenous variation. The first stage regression is:
  \[
  X_i = \pi_0 + \pi_1 Z_1 + \pi_2 Z_2 + \cdots + \pi_k Z_k + u
  \]
- **Obtain Predicted Values**: The fitted values from the regression are used to create instrumented versions of the endogenous variables.

#### 2.4 Constructing the Instrumented Data
- **Create Instrumented Variables**: Use the fitted values \( \hat{X} \) from the first stage regression to construct the instrumented data \( \hat{X}_i \).

#### 2.5 Principal Component Analysis on Instrumented Data
- **Compute Covariance Matrix**: Calculate the covariance matrix of the instrumented data \( \hat{X}_i \).
- **Eigenvalue Decomposition**: Perform eigenvalue decomposition on the covariance matrix to obtain eigenvalues and eigenvectors.
- **Select Principal Components**: Choose the principal components with the largest eigenvalues, explaining the most variance in the data.
- **Project Data onto Principal Components**: Project the original data onto the selected principal components to reduce dimensionality.

### 3. Applying IPCA to FX Returns
#### 3.1 Empirical Implementation
- **Model Estimation**: The paper estimates the IPCA model by combining the instrumented variables and performing PCA. This allows for the extraction of latent factors that account for time-varying betas.
- **Validation and Testing**: The model's performance is validated using both in-sample and out-of-sample tests. The IPCA model demonstrates superior predictive power compared to traditional PCA and random walk models.

#### 3.2 Key Findings
- **Out-of-Sample Predictability**: IPCA outperforms the random walk and PCA models in terms of out-of-sample predictability, indicating its robustness in capturing time-varying risk premiums.
- **Significance of Instrumental Variables**: The study finds that interest rate differentials, stock market momentum, and idiosyncratic volatility are significant predictors of FX returns, confirming the effectiveness of the chosen instruments.

### 4. Practical Implementation of IPCA in Python (Contextual Example)
Below is a practical example of implementing the IPCA algorithm in Python, contextualized for the research paper's FX returns analysis:

```python
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

# Step 1: Data Preparation
# Example data (X: endogenous variables, Z: instrumental variables)
# Assume X and Z are pre-collected and standardized data arrays
X = np.random.rand(100, 2)  # Placeholder for actual FX returns data
Z = np.random.rand(100, 2)  # Placeholder for actual instrumental variables

# Standardize the data
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
Z_scaled = scaler.fit_transform(Z)

# Step 2: First Stage Regression
# Regress each endogenous variable on the instruments
reg1 = LinearRegression().fit(Z_scaled, X_scaled[:, 0])
X1_hat = reg1.predict(Z_scaled)

reg2 = LinearRegression().fit(Z_scaled, X_scaled[:, 1])
X2_hat = reg2.predict(Z_scaled)

# Step 3: Constructing the Instrumented Data
X_hat = np.column_stack((X1_hat, X2_hat))

# Step 4: Principal Component Analysis on Instrumented Data
# Compute covariance matrix
cov_matrix = np.cov(X_hat, rowvar=False)

# Eigenvalue decomposition
eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)

# Select principal components (e.g., select top 2 components)
num_components = 2
principal_components = eigenvectors[:, -num_components:]

# Project data onto principal components
X_reduced = X_hat.dot(principal_components)

print("Reduced-dimensional representation:\n", X_reduced)
```

---

### Applying IPCA to FX Returns: Workflow

#### 1. Introduction to the Workflow
The IPCA model combines the flexibility of PCA with the robustness of instrumental variables to handle endogeneity in the explanatory variables. The goal is to predict FX returns by extracting latent factors and accounting for time-varying betas.

#### 2. Workflow Steps

##### Step 1: Data Preparation
1. **Collect Data**:
   - Gather FX spot and forward rates from data sources like Datastream.
   - Collect macroeconomic and financial variables (e.g., interest rate differentials, stock market momentum, idiosyncratic volatility) that will serve as instruments.

2. **Standardize Data**:
   - Standardize the FX return data and instrumental variables to have zero mean and unit variance.

##### Step 2: Model Specification
1. **Define the Model**:
   - Specify the regression model with FX returns as the dependent variable and macroeconomic/financial variables as the endogenous explanatory variables.

2. **Select Instruments**:
   - Choose instrumental variables that are theoretically justifiable and satisfy the relevance and exogeneity conditions.

##### Step 3: First Stage Regression
1. **Regress Endogenous Variables on Instruments**:
   - For each endogenous variable, perform a regression on the selected instrumental variables to isolate the exogenous variation.
   - Example regression for one endogenous variable \(X_i\):
     \[
     X_i = \pi_0 + \pi_1 Z_1 + \pi_2 Z_2 + \cdots + \pi_k Z_k + u
     \]

2. **Obtain Predicted Values**:
   - Compute the fitted values (predicted values) from the first stage regression for each endogenous variable. These fitted values represent the instrumented versions of the endogenous variables.

##### Step 4: Constructing the Instrumented Data
1. **Create Instrumented Variables**:
   - Use the fitted values obtained from the first stage regression to create instrumented versions of the endogenous explanatory variables.

##### Step 5: Principal Component Analysis on Instrumented Data
1. **Compute Covariance Matrix**:
   - Calculate the covariance matrix of the instrumented data.

2. **Eigenvalue Decomposition**:
   - Perform eigenvalue decomposition on the covariance matrix to obtain the eigenvalues and eigenvectors.
   - The eigenvalues represent the amount of variance explained by each principal component, while the eigenvectors represent the directions of the principal components.

3. **Select Principal Components**:
   - Choose the principal components that explain the most variance in the instrumented data. Typically, components with the largest eigenvalues are selected.

4. **Project Data onto Principal Components**:
   - Project the original data onto the selected principal components to obtain the reduced-dimensional representation.

##### Step 6: Model Estimation and Validation
1. **Model Estimation**:
   - Estimate the IPCA model by combining the instrumented variables and performing PCA. This involves solving the optimization problem to minimize the sum of squared residuals subject to constraints on the factor loadings.
     \[
     \min_{\Gamma_{\beta}, \Gamma_{\alpha}, F} \sum_{t=1}^{T-1} (r_{t+1} - Z_t \Gamma_{\alpha} - Z_t \Gamma_{\beta} f_{t+1})^T (r_{t+1} - Z_t \Gamma_{\alpha} - Z_t \Gamma_{\beta} f_{t+1})
     \]
   - Where \( r_{t+1} \) is the return vector, \( Z_t \) is the matrix of country characteristics, \( \Gamma_{\alpha} \) and \( \Gamma_{\beta} \) are coefficient matrices, and \( f_{t+1} \) are the latent factors.

2. **Validation and Testing**:
   - Evaluate the model's performance using in-sample and out-of-sample tests.
   - Compare the predictive power of the IPCA model with benchmarks like the random walk model and traditional PCA.

#### Example of Applying IPCA to FX Returns in Python
Here‚Äôs a practical example of implementing the IPCA algorithm in Python, contextualized for FX returns analysis:

```python
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

# Step 1: Data Preparation
# Example data (X: endogenous variables, Z: instrumental variables)
# Assume X and Z are pre-collected and standardized data arrays
X = np.random.rand(100, 2)  # Placeholder for actual FX returns data
Z = np.random.rand(100, 2)  # Placeholder for actual instrumental variables

# Standardize the data
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
Z_scaled = scaler.fit_transform(Z)

# Step 2: First Stage Regression
# Regress each endogenous variable on the instruments
reg1 = LinearRegression().fit(Z_scaled, X_scaled[:, 0])
X1_hat = reg1.predict(Z_scaled)

reg2 = LinearRegression().fit(Z_scaled, X_scaled[:, 1])
X2_hat = reg2.predict(Z_scaled)

# Step 3: Constructing the Instrumented Data
X_hat = np.column_stack((X1_hat, X2_hat))

# Step 4: Principal Component Analysis on Instrumented Data
# Compute covariance matrix
cov_matrix = np.cov(X_hat, rowvar=False)

# Eigenvalue decomposition
eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)

# Select principal components (e.g., select top 2 components)
num_components = 2
principal_components = eigenvectors[:, -num_components:]

# Project data onto principal components
X_reduced = X_hat.dot(principal_components)

print("Reduced-dimensional representation:\n", X_reduced)

# Step 6: Model Estimation and Validation (Conceptual)
# In practice, you would integrate the reduced data into a regression or forecasting model,
# and then evaluate its performance using in-sample and out-of-sample tests.
```


### Step 2: Define the Factor Model and Step 3: Dynamic Factor Loadings with FX Example from the Paper

#### Step 2: Define the Factor Model

**Mathematical Interpretation:**
- **Factor Model Setup**: The factor model assumes that the currency return \( r_{i,t+1} \) for currency \( i \) at time \( t+1 \) is influenced by latent factors \( f_{t+1} \). The model is defined as:
  \[
  r_{i,t+1} = \alpha_{i,t} + \beta_{i,t} f_{t+1} + \epsilon_{i,t+1}
  \]
  - \( \alpha_{i,t} \): Intercept term (base level of return for currency \( i \) at time \( t \)).
  - \( \beta_{i,t} \): Factor loadings (how strongly each factor \( f_{t+1} \) affects the return of currency \( i \) at time \( t+1 \)).
  - \( f_{t+1} \): Latent factors (unobservable common factors affecting all currencies at time \( t+1 \)).
  - \( \epsilon_{i,t+1} \): Error term (unexplained part of the return for currency \( i \) at time \( t+1 \)).

**Layman Explanation:**
- **Basic Assumption**: Imagine that the return (profit or loss) on a currency like the Euro or Yen is influenced by some hidden, common factors (like global economic conditions). The model also includes a base level return and some random noise.

#### FX Example from the Paper:
- The paper collects returns on currencies from G10 countries (like USD, EUR, JPY) and assumes that these returns are influenced by common factors such as interest rates and market volatility.

#### Step 3: Dynamic Factor Loadings

**Mathematical Interpretation:**
- **Dynamic Loadings**: Unlike static models, IPCA allows the intercept (\( \alpha_{i,t} \)) and the factor loadings (\( \beta_{i,t} \)) to vary over time based on observable characteristics \( z_{i,t} \). This is done to account for changing economic conditions. The dynamic factor loadings are modeled as:
  \[
  \alpha_{i,t} = z_{i,t}^\top \Gamma_\alpha + \nu_{\alpha,i,t}
  \]
  \[
  \beta_{i,t} = z_{i,t}^\top \Gamma_\beta + \nu_{\beta,i,t}
  \]
  - \( z_{i,t} \): Vector of observable characteristics for currency \( i \) at time \( t \) (e.g., interest rates, inflation rates).
  - \( \Gamma_\alpha \) and \( \Gamma_\beta \): Matrices of coefficients linking the characteristics to the intercept and factor loadings.
  - \( \nu_{\alpha,i,t} \) and \( \nu_{\beta,i,t} \): Error terms for the intercept and factor loadings.

**Layman Explanation:**
- **Changing Influence**: The impact of economic factors on currency returns isn't fixed; it changes over time. For example, the influence of interest rates on currency returns might be different during a financial crisis compared to a stable period. The model uses current economic data to adjust these influences dynamically.

#### FX Example from the Paper:
- **Observable Characteristics**: The paper uses economic indicators like medium-term interest rate differentials, stock market momentum, and idiosyncratic volatility as observable characteristics \( z_{i,t} \).
- **Dynamic Adjustments**:
  - For example, the impact of the interest rate differential on the Euro's return might change over time. During periods of high market volatility, the sensitivity (or factor loading) of the Euro's return to interest rate differentials might increase.

### Detailed Example

Let's walk through a simplified example using interest rate differentials:

1. **Data Collection**:
   - Collect monthly returns for the Euro (EUR/USD) from 2008 to 2020.
   - Gather economic indicators like the interest rate differential between the Eurozone and the US, stock market momentum, and idiosyncratic volatility.

2. **Define the Factor Model**:
   - Assume the Euro's return is influenced by a common factor (e.g., global economic condition) and a base return.
   - The factor model is:
     \[
     r_{\text{EUR},t+1} = \alpha_{\text{EUR},t} + \beta_{\text{EUR},t} f_{t+1} + \epsilon_{\text{EUR},t+1}
     \]

3. **Dynamic Factor Loadings**:
   - Allow the base return (\( \alpha_{\text{EUR},t} \)) and the sensitivity to the common factor (\( \beta_{\text{EUR},t} \)) to vary based on current economic indicators:
     \[
     \alpha_{\text{EUR},t} = z_{\text{EUR},t}^\top \Gamma_\alpha + \nu_{\alpha,\text{EUR},t}
     \]
     \[
     \beta_{\text{EUR},t} = z_{\text{EUR},t}^\top \Gamma_\beta + \nu_{\beta,\text{EUR},t}
     \]

4. **Observable Characteristics**:
   - Let \( z_{\text{EUR},t} \) include the medium-term interest rate differential, stock market momentum, and idiosyncratic volatility.
   - For instance, if the medium-term interest rate differential increases, the model will adjust the factor loading (\( \beta_{\text{EUR},t} \)) to reflect this new information.

5. **Combining the Model**:
   - Substitute the dynamic expressions into the factor model:
     \[
     r_{\text{EUR},t+1} = z_{\text{EUR},t}^\top \Gamma_\alpha + z_{\text{EUR},t}^\top \Gamma_\beta f_{t+1} + \epsilon^*_{\text{EUR},t+1}
     \]
   - This combined model now accounts for changing economic conditions and their impact on the Euro's returns.

By using IPCA, the paper dynamically adjusts the factor loadings based on current economic indicators, providing a more accurate and flexible model for predicting FX returns. This method allows the model to capture time-varying relationships between economic factors and currency returns, which is crucial for accurate predictions in the volatile forex market.

## **Table of Contents:**

1. [Introduction](https://github.com/aditya-saxena-7/Dynamic-Beta-Variability-in-Foreign-Exchange-Returns-Using-Instrumented-PCA/blob/main/Introduction.md)

2. [Methodology](https://github.com/aditya-saxena-7/Dynamic-Beta-Variability-in-Foreign-Exchange-Returns-Using-Instrumented-PCA/blob/main/Methodology.md)

3. [Data and Preliminary Findings](https://github.com/aditya-saxena-7/Dynamic-Beta-Variability-in-Foreign-Exchange-Returns-Using-Instrumented-PCA/blob/main/Data%20and%20Preliminary%20Findings.md)

4. [Empirical Findings](https://github.com/aditya-saxena-7/Dynamic-Beta-Variability-in-Foreign-Exchange-Returns-Using-Instrumented-PCA/blob/main/Empirical%20Findings.md)

5. [Interpreting IPCA Factors](https://github.com/aditya-saxena-7/Dynamic-Beta-Variability-in-Foreign-Exchange-Returns-Using-Instrumented-PCA/blob/main/Interpreting%20IPCA%20Factors.md)

6. [Robustness and discussions](https://github.com/aditya-saxena-7/Dynamic-Beta-Variability-in-Foreign-Exchange-Returns-Using-Instrumented-PCA/blob/main/Robustness%20and%20discussions.md)

7. [Conclusion](https://github.com/aditya-saxena-7/Dynamic-Beta-Variability-in-Foreign-Exchange-Returns-Using-Instrumented-PCA/blob/main/Conclusion.md)
